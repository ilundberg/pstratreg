[{"path":"index.html","id":"welcome","chapter":"Welcome!","heading":"Welcome!","text":"Warning. website documents R package development. Expect changes. encourage try package email us suggestions.1. can also see draft slides presentation project.website documents pstratreg package R. package helps study causal effects treatment values cause outcomes non-existent units.Possible applications includea labor market intervention outcome hourly wage, people unemployeda medical intervention outcome health metric, people die measureda sociological study outcome involves one’s spouse, people divorce never marry thus spouseThis package provides regression-based methods principal stratification rely parametric models useful settings one hopes adjust many confounders.","code":""},{"path":"index.html","id":"getting-started","chapter":"Welcome!","heading":"Getting started","text":"get started, first install R RStudio. install package.Now head next page see types questions package can help answer.project joint work Ian Lundberg (UCLA, ianlundberg@ucla.edu) Soonhong Cho (UCLA, tnsehdtm@gmail.com).","code":"\ndevtools::install_github(\"ilundberg/pstratreg\")"},{"path":"the-goal.html","id":"the-goal","chapter":"1 The goal","heading":"1 The goal","text":"Average causal effects undefined outcomes exist. example, consider two people eligible job training intervention.social scientist might study average causal effect intervention future hourly wages. without job training, William employed . wage ?? exist. result, average causal effect exist. Principal stratification method estimate average causal effects subpopulation excludes people like William, effect undefined.read . original ideas, see Frangakis & Rubin (2002) Zhang & Rubin (2003). recent introduction, see Miratrix et al. (2018).page tutorial ideas behind principal stratification. next page discusses regression setting focus package. Subsequent pages show package functionality.","code":""},{"path":"the-goal.html","id":"defining-principal-strata","chapter":"1 The goal","heading":"1.1 Defining principal strata","text":"Let \\(M_i\\) binary mediator (e.g., employment) determines whether outcome exists unti \\(\\). Let \\(Y_i\\) outcome, \\(Y\\) undefined \\(M = 0\\). Let \\(\\{M_i^1,M_i^0\\}\\) \\(\\{Y_i^1,Y_i^0\\}\\) potential values mediator outcome take unit \\(\\) job training job training. table gave values \\(\\{Y_i^1,Y_i^0\\}\\).Define four principal strata units effect intervention mediator valueIn example, Javier member always stratum William member induced stratum.","code":""},{"path":"the-goal.html","id":"target-population-the-always-stratum","chapter":"1 The goal","heading":"1.2 Target population: The always stratum","text":"average causal effect \\(E(Y^1 - Y^0)\\) defined “Always” stratum.induced stratum, \\(Y^0\\) undefined, effect \\(Y^1 - ??\\)blocked stratum, \\(Y^1\\) undefined, effect \\(?? - Y^0\\)never stratum, undefined, effect \\(?? - ??\\)causal estimand therefore average causal effect always stratum.\\[E(Y^1 - Y^0 \\mid S = \\text{Always})\\]","code":""},{"path":"the-goal.html","id":"fundamental-problem-strata-are-latent","chapter":"1 The goal","heading":"1.3 Fundamental problem: Strata are latent","text":"Suppose William received job training. observe $26 wage. know employed without job training. William received job training, observed data know either always stratum induced stratum.can observed treatment value \\(D_i\\) mediator value \\(M_i\\). combination values mixture two principal strata.","code":""},{"path":"the-goal.html","id":"solution-step-1-make-an-assumption","chapter":"1 The goal","heading":"1.4 Solution step 1: Make an assumption","text":"Assumptions can simplify problem, can plausible settings. focus two versions one assumption.example, positive monotonicity assumption may credible: job training unlikely block anyone employment. settings, negative monotonicity assumption credible. treatment criminal record one’s resume, treatment might block employment unlikely induce employment.positive monotonicity, latent strata become observable.example, suppose Javier assigned job training, observed employed. positive monotonicity, know Javier always stratum employed without job training, thus surely employed job training.","code":""},{"path":"the-goal.html","id":"solution-step-2-bound-the-average-effect-in-the-always-stratum","chapter":"1 The goal","heading":"1.5 Solution step 2: Bound the average effect in the always stratum","text":"Suppose assume positive monotonicity, observe data four people randomized treatment condition.-job-training condition, observe following four peopleThe stratum column sometimes known assumption: Jamal Sandra employed despite job training, surely employed counterfactual world job training (positive monotonicity). Oscar Nancy might might employed counterfactual world received job training.Four people randomized treatment: job trainingThe stratum column four treated people always unknown, positive monotonicity might might employed despite job training.comparing frequency ?? tables, can estimate job training reduces employment 50 percentage points. tells us size induced stratum.\\[\\hat{P}(S = \\text{Induced}) = 0.5\\]receiving job training employed, data also suggest never-employed stratum empty.\\[\\hat{P}(S = \\text{Never}) = 0\\]Thus, example estimate 50% people always employed 50% induced employment exposed job training. Thus half {Nia, Steven, Maya, Hugo} always-employed.half? impossible know. therefore bound expected outcome treatment.upper bound, assume highest-valued half treated units always-employed ones\nNia Steven always employed\nMaya Hugo induced\n\\(\\hat{E}_\\text{Upper}(Y^1\\mid S = \\text{Always}) = \\frac{32+40}{2} = \\$36\\)\nNia Steven always employedMaya Hugo induced\\(\\hat{E}_\\text{Upper}(Y^1\\mid S = \\text{Always}) = \\frac{32+40}{2} = \\$36\\)lower bound, assume lowest-valued half treated units always-employed ones\nNia Steven induced\nMaya Hugo always employed\n\\(\\hat{E}_\\text{Lower}(Y^1\\mid S = \\text{Always}) = \\frac{25+29}{2} = \\$27\\)\nNia Steven inducedMaya Hugo always employed\\(\\hat{E}_\\text{Lower}(Y^1\\mid S = \\text{Always}) = \\frac{25+29}{2} = \\$27\\)positive monotonicity untreated individuals must always-employed, point estimate outcome control\\[\\hat{E}(Y^0\\mid S = \\text{Always}) = \\$18\\]difference tells us average causal effect job training wages always employed $27 - $18 = $9 $36 - $18 = $18.","code":""},{"path":"why-regression.html","id":"why-regression","chapter":"2 Why regression","heading":"2 Why regression","text":"goal package support parametric model-based principal stratification. page motivates choice: want model?Parametric regression models make principal stratification bounds applicable social science settings many covariates. One setting causal inference observational settings. setting, might want statistically adjust covariate vector \\(\\vec{X}\\).\\(\\vec{X}\\) can take discrete values, one can carry principal stratification within stratum \\(\\vec{X}\\)\\(\\vec{X}\\) can take many values, possible vector value \\(\\vec{X}_i\\) uniqueIn latter case, need model-based principal stratification.Model mediator\nFit model mediator \\(M\\)\nEstimate probability stratum unit\nFit model mediator \\(M\\)Estimate probability stratum unitModel outcome\nFit model outcome \\(Y\\mid = 1, M = 1, \\vec{X}\\)\nExample: Model distribution wages employed job training recipients\n\nFit model outcome \\(Y\\mid = 0, M = 1, \\vec{X}\\)\nExample: Model distribution wages employed job training recipients\n\nBound assuming proportion induced (1) upper lower portion conditional covariates\nFit model outcome \\(Y\\mid = 1, M = 1, \\vec{X}\\)\nExample: Model distribution wages employed job training recipients\nExample: Model distribution wages employed job training recipientsFit model outcome \\(Y\\mid = 0, M = 1, \\vec{X}\\)\nExample: Model distribution wages employed job training recipients\nExample: Model distribution wages employed job training recipientsBound assuming proportion induced (1) upper lower portion conditional covariates","code":""},{"path":"why-regression.html","id":"upper-bound-left---right","chapter":"2 Why regression","heading":"2.0.1 Upper bound: Left - Right","text":"","code":""},{"path":"why-regression.html","id":"lower-bound-left---right","chapter":"2 Why regression","heading":"2.0.2 Lower bound: Left - Right","text":"","code":""},{"path":"basic-functionality.html","id":"basic-functionality","chapter":"3 Basic functionality","heading":"3 Basic functionality","text":"page illustrates basic functionality pstratreg function. function conducts parametric principal stratification analysis estimate average causal effect among always-valid subgroup whose outcome exist either treatment condition.Jargon? Start first page goal!package automates process toestimate mediator modelestimate outcome model\nallowing heteroskedasticity needed\nallowing heteroskedasticity neededcalculate conditional probability always-validimplement monotonicity assumptionsbound estimates using conditional outcome distribution proportion always-valid subgroupreturn estimates, conditional population subgroups requested","code":""},{"path":"basic-functionality.html","id":"simulate-data","chapter":"3 Basic functionality","heading":"3.1 Simulate data","text":"first simulate data illustration.data four variablescontinuous confounder xbinary treatment abinary mediator mcontinuous outcome y\ny NA m = FALSE\ny NA m = FALSE","code":"\nlibrary(tidyverse)\nlibrary(pstratreg)\ndata <- pstratreg_sim(n = 100)#>             x     a     s          y\n#> 1  0.05982853 FALSE  TRUE -0.8101817\n#> 2 -1.33520583 FALSE  TRUE -2.2969309\n#> 3 -0.82352375  TRUE  TRUE -1.8947736\n#> 4  0.58452730  TRUE FALSE         NA\n#> 5  0.55000337  TRUE  TRUE  1.6149997"},{"path":"basic-functionality.html","id":"the-pstratreg-function","chapter":"3 Basic functionality","heading":"3.2 The pstratreg function","text":"call runs principal stratification regression analysis default options, returning estimates average treatment effect among latent stratum valid outcomes regardless treatment.","code":"\nresult <- pstratreg(\n  formula_y = formula(y ~ x*a),\n  formula_s = formula(s ~ x*a),\n  data = data,\n  treatment_name = \"a\"\n)#> Effect on survival, where S = 1 indicates the outcome exists\n#> # A tibble: 1 × 3\n#>      s0    s1 effect_s\n#>   <dbl> <dbl>    <dbl>\n#> 1 0.710 0.870    0.160\n#> \n#> Effect on outcome among those who would have a valid outcome regardless of treatment\n#> # A tibble: 1 × 2\n#>   effect_y_lower effect_y_upper\n#>            <dbl>          <dbl>\n#> 1          0.107           1.66"},{"path":"basic-functionality.html","id":"positive-monotonicity","chapter":"3 Basic functionality","heading":"3.3 Positive monotonicity","text":"believe TRUE value treatment never causes outcome undefined, might add monotonicity_positive = TRUE option.Sometimes, monotonicity assumption disagrees empirical estimates least cases. example, assume treatment never prevents valid outcome empirically estimate treatment increases probability treatment increases value mediator subgroups. happens, package issues warning.Empirical monotonicity violations may non-troubling; can occur estimates due random chance sampling variability. user assumed monotonicity, package assumes violations arise purely estimation errors. predicted values mediator treatment condition cases forced equal, midpoint two predicted values.Generally, warning tells monotonicity violated small percent cases, may warranted proceed. monotonicity empirically violated many cases, may need rethink assumption.","code":"\nresult <- pstratreg(\n  formula_y = formula(y ~ x*a),\n  formula_s = formula(s ~ x*a),\n  data = data,\n  treatment_name = \"a\",\n  monotonicity_positive = TRUE\n)#> Effect on survival, where S = 1 indicates the outcome exists\n#> # A tibble: 1 × 3\n#>      s0    s1 effect_s\n#>   <dbl> <dbl>    <dbl>\n#> 1 0.710 0.870    0.160\n#> \n#> Effect on outcome among those who would have a valid outcome regardless of treatment\n#> # A tibble: 1 × 2\n#>   effect_y_lower effect_y_upper\n#>            <dbl>          <dbl>\n#> 1          0.625           1.14"},{"path":"basic-functionality.html","id":"negative-monotonicity","chapter":"3 Basic functionality","heading":"3.4 Negative monotonicity","text":"Conversely, can assume negative monotonicity monotonicity_negative = TRUE. sure negative monotonicity , see previous page big idea!particular simulation, negative monotonicity hold see warning appropriately alerts us monotonicity frequently empirically violated.","code":"\nresult <- pstratreg(\n  formula_y = formula(y ~ x*a),\n  formula_s = formula(s ~ x*a),\n  data = data,\n  treatment_name = \"a\",\n  monotonicity_negative = TRUE\n)\n#> Warning in pstratreg(formula_y = formula(y ~ x * a), formula_s = formula(s ~ : Monotonicity violated in 100 % of cases\n#> Forcing s1_trunc = s0_trunc at midpoint of estimates for those#> Effect on survival, where S = 1 indicates the outcome exists\n#> # A tibble: 1 × 3\n#>      s0    s1 effect_s\n#>   <dbl> <dbl>    <dbl>\n#> 1 0.710 0.870    0.160\n#> \n#> Effect on outcome among those who would have a valid outcome regardless of treatment\n#> # A tibble: 1 × 2\n#>   effect_y_lower effect_y_upper\n#>            <dbl>          <dbl>\n#> 1          0.867          0.867"},{"path":"basic-functionality.html","id":"aggregate-in-subgroups","chapter":"3 Basic functionality","heading":"3.5 Aggregate in subgroups","text":"Instead sample average effect estimates, might want estimate within subgroups defined grouping variable data. group_vars argument allows specify vector variable names data within aggregate results.First create groups illustrationand apply function estimate within groups.","code":"\ndata_with_groups <- data %>%\n  mutate(group1 = x < -.5,\n         group2 = x > .5)#>             x     a     s          y group1 group2\n#> 1  0.05982853 FALSE  TRUE -0.8101817  FALSE  FALSE\n#> 2 -1.33520583 FALSE  TRUE -2.2969309   TRUE  FALSE\n#> 3 -0.82352375  TRUE  TRUE -1.8947736   TRUE  FALSE\n#> 4  0.58452730  TRUE FALSE         NA  FALSE   TRUE\n#> 5  0.55000337  TRUE  TRUE  1.6149997  FALSE   TRUE\n#> 6  0.44628076  TRUE  TRUE  2.8372122  FALSE  FALSE\nresult <- pstratreg(\n  formula_y = formula(y ~ x*a),\n  formula_s = formula(s ~ x*a),\n  data = data_with_groups,\n  treatment_name = \"a\",\n  group_vars = c(\"group1\",\"group2\")\n)#> Effect on survival, where S = 1 indicates the outcome exists\n#> # A tibble: 3 × 5\n#>   group1 group2    s0    s1 effect_s\n#>   <lgl>  <lgl>  <dbl> <dbl>    <dbl>\n#> 1 FALSE  FALSE  0.749 0.887   0.138 \n#> 2 FALSE  TRUE   0.880 0.934   0.0539\n#> 3 TRUE   FALSE  0.476 0.780   0.304 \n#> \n#> Effect on outcome among those who would have a valid outcome regardless of treatment\n#> # A tibble: 3 × 4\n#> # Groups:   group1, group2 [3]\n#>   group1 group2 effect_y_lower effect_y_upper\n#>   <lgl>  <lgl>           <dbl>          <dbl>\n#> 1 FALSE  FALSE           0.170           1.53\n#> 2 TRUE   FALSE          -1.36            2.45\n#> 3 FALSE  TRUE            0.731           1.44"},{"path":"basic-functionality.html","id":"sample-weights","chapter":"3 Basic functionality","heading":"3.6 Sample weights","text":"case weights sampling unequal probabilities, can provided vector length nrow(data) using weights argument.generate hypothetical weightsand call function. Note glm() used internally estimate logistic regression create warning non-integer #successes binomial glm! expected weights used function.","code":"\nsim_weights <- runif(nrow(data))\nresult <- pstratreg(\n  formula_y = formula(y ~ x*a),\n  formula_s = formula(s ~ x*a),\n  data = data,\n  treatment_name = \"a\",\n  weights = sim_weights\n)\n#> Warning in eval(family$initialize): non-integer #successes\n#> in a binomial glm!#> Effect on survival, where S = 1 indicates the outcome exists\n#> # A tibble: 1 × 3\n#>      s0    s1 effect_s\n#>   <dbl> <dbl>    <dbl>\n#> 1 0.700 0.833    0.133\n#> \n#> Effect on outcome among those who would have a valid outcome regardless of treatment\n#> # A tibble: 1 × 2\n#>   effect_y_lower effect_y_upper\n#>            <dbl>          <dbl>\n#> 1         0.0558           2.00"},{"path":"relaxing-homoskedasticity.html","id":"relaxing-homoskedasticity","chapter":"4 Relaxing homoskedasticity","heading":"4 Relaxing homoskedasticity","text":"Model-based principal stratification bounds involve model conditional distribution outcome, just conditional mean. goal, one might concerned homoskedasticity assumption.Homoskedasticity: assumption conditional outcome variance equal values predictors.commonly assumed Ordinary Least Squares, homoskedasticity assumption can relaxed. currently support parametric model heteroskedasticity based ideas variance function regression (Western & Bloome 2009).","code":""},{"path":"relaxing-homoskedasticity.html","id":"model-the-conditional-mean","chapter":"4 Relaxing homoskedasticity","heading":"4.1 Model the conditional mean","text":"begin ordinary least squares outcome model, homoskedastic case,\\[\\begin{aligned}\nE(Y\\mid \\vec{X},,M = 1) =\\alpha + \\hat\\beta  + \\vec{X}\\vec\\gamma + \\vec{X}'\\vec\\eta\n\\end{aligned}\\]\\(\\) binary treatment, \\(\\vec{X}\\) vector measured confounders, \\(M = 1\\) mediator indicating outcome valid. Let \\(\\hat{Y}_i\\) predicted value unit \\(\\) model.","code":""},{"path":"relaxing-homoskedasticity.html","id":"model-the-conditional-variance","chapter":"4 Relaxing homoskedasticity","heading":"4.2 Model the conditional variance","text":"next allow conditional variance \\(Y\\) vary function \\(\\) \\(\\vec{X}\\). first define squared residual\\[\\hat\\epsilon^2 = \\left(Y - \\hat{Y}\\right)^2\\]\nassumption \\(\\hat\\epsilon\\) normally distributed, squared residual \\(\\hat\\epsilon^2\\) follows Gamma distribution mean equal conditional variance \\(\\sigma^2(\\vec{X},,M=1)\\). therefore model \\(\\hat\\epsilon^2\\) Gamma GLM log link function, using parametric linear predictor one .\\[\\begin{aligned}\n\\log(\\sigma^2(\\vec{X},,M=1)) = \\lambda + \\delta  + \\vec{X}'\\vec\\nu + \\vec{X}'\\vec\\omega\n\\end{aligned}\\]Predictions model (exponentiated) estimates conditional variance, \\(\\hat{V}(Y\\mid \\vec{X},,M=1)\\) observed predictors unit. make predictions treatment control conditions.\\[\\begin{aligned}\n\\hat{V}(Y\\mid \\vec{X},= 1,M=1) &= \\text{exp}\\left[\\hat\\lambda + \\hat\\delta  + \\vec{X}'\\left(\\hat{\\vec\\nu} + \\hat{\\vec\\omega}\\right)\\right] \\\\\n\\hat{V}(Y\\mid \\vec{X},= 0,M=1) &= \\text{exp}\\left[\\hat\\lambda + \\vec{X}'\\hat{\\vec\\nu}\\right] \\\\\n\\end{aligned}\\]","code":""},{"path":"relaxing-homoskedasticity.html","id":"in-code","chapter":"4 Relaxing homoskedasticity","heading":"4.3 In code","text":"can relax homskedasticity assumption homoskedastic = FALSE argument. estimates variance function regression () using predictor model formula formula_y.data setup , can estimate models.Optionally, can specify separate model formula model squared residuals may simpler model formula used \\(Y\\), might done model formula involves many parameters see errors internal glm() call convergence variance regression.","code":"\nlibrary(tidyverse)\nlibrary(pstratreg)\ndata <- pstratreg_sim(n = 100)\nresult <- pstratreg(\n  formula_y = formula(y ~ x*a),\n  formula_s = formula(s ~ x*a),\n  data = data,\n  treatment_name = \"a\",\n  homoskedastic = FALSE\n)#> Effect on survival, where S = 1 indicates the outcome exists\n#> # A tibble: 1 × 3\n#>      s0    s1 effect_s\n#>   <dbl> <dbl>    <dbl>\n#> 1 0.742 0.877    0.135\n#> \n#> Effect on outcome among those who would have a valid outcome regardless of treatment\n#> # A tibble: 1 × 2\n#>   effect_y_lower effect_y_upper\n#>            <dbl>          <dbl>\n#> 1         0.0158           1.79\nresult <- pstratreg(\n  formula_y = formula(y ~ x*a),\n  formula_s = formula(s ~ x*a),\n  formula_sq_resid = formula(~ x + a),\n  data = data,\n  treatment_name = \"a\",\n  homoskedastic = FALSE\n)#> Effect on survival, where S = 1 indicates the outcome exists\n#> # A tibble: 1 × 3\n#>      s0    s1 effect_s\n#>   <dbl> <dbl>    <dbl>\n#> 1 0.742 0.877    0.135\n#> \n#> Effect on outcome among those who would have a valid outcome regardless of treatment\n#> # A tibble: 1 × 2\n#>   effect_y_lower effect_y_upper\n#>            <dbl>          <dbl>\n#> 1         0.0815           1.72"},{"path":"standard-errors.html","id":"standard-errors","chapter":"5 Standard errors","heading":"5 Standard errors","text":"Appropriate standard errors depend application-specific knowledge data generated. example, appropriate standard errors sampling variability simple random samples, sampling variability complex samples, finite-sample inference variation random treatment assignment.particular case simple random samples, package supports standard error estimation nonparametric bootstrap 95% confidence intervals Normal approximation using estimated standard error.first set environmentand simulate dataand produce point estimates call pstratreg.estimate standard errors confidence intervals, hand output call pstratreg pstratreg_se function, optionally specifying number r bootstrap samples.output call pstratreg_se data frame containing estimates inferential quantities.See end page glossary estimand terms output.","code":"\nlibrary(tidyverse)\nlibrary(pstratreg)\ndata <- pstratreg_sim(n = 100)\npstratreg.out <- pstratreg(\n  formula_y = formula(y ~ x*a),\n  formula_s = formula(s ~ x*a),\n  data = data,\n  treatment_name = \"a\"\n)\nresult_with_se <- pstratreg_se(pstratreg.out, r = 100)#> # A tibble: 2 × 5\n#>   estimand       estimate    se ci.min ci.max\n#>   <chr>             <dbl> <dbl>  <dbl>  <dbl>\n#> 1 effect_y_lower   -0.178 0.453  -1.07  0.710\n#> 2 effect_y_upper    1.91  0.350   1.22  2.60"},{"path":"standard-errors.html","id":"visualize-the-result","chapter":"5 Standard errors","heading":"5.1 Visualize the result","text":"One way use output create visualizations using ggplot. example, code visualizes bounded effects outcome.","code":"\nresult_with_se %>%\n  filter(estimand %in% c(\"effect_y_lower\",\"effect_y_naive\",\"effect_y_upper\")) %>%\n  mutate(estimand_label = case_when(\n    estimand == \"effect_y_lower\" ~ \"(1)\\nLower Bound\",\n    estimand == \"effect_y_naive\" ~ \"(2)\\nEstimate if No\\nPost-Treatment\\nSelection\",\n    estimand == \"effect_y_upper\" ~ \"(3)\\nUpper Bound\"\n  )) %>%\n  ggplot(aes(x = estimand_label, y = estimate,\n             ymin = ci.min, ymax = ci.max)) +\n  geom_point() +\n  geom_errorbar() +\n  ylab(\"Average Causal Effect on Outcome\\nAmong the Always-Valid\") +\n  scale_x_discrete(name = \"Bound Estimates\")"},{"path":"standard-errors.html","id":"glossary-of-estimands-that-result","chapter":"5 Standard errors","heading":"5.2 Glossary of estimands that result","text":"","code":""}]
